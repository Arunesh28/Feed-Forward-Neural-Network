{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.datasets import fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import sklearn.model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "import wandb\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion Mnist Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, Y), (X_test, Y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_classes = len(np.unique(Y))\n",
    "# for i in range(num_classes):\n",
    "unique_classes = [X[np.where(Y == i)[0][0]] for i in range(num_classes)]\n",
    "class_names = [\"T-shirt\", \"Trouser\", \"Pullover\", \"Dress\",\n",
    "               \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "for i in range(1, num_classes+1):\n",
    "    plt.subplot(2, 5, i)\n",
    "    plt.imshow(unique_classes[i-1], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(class_names[i-1], fontdict={'fontsize': 7})\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Training DataSet = 54000\n",
      "Size of Validation DataSet = 6000\n",
      "Size of Test DataSet = 10000\n",
      "Number of classes = 10\n",
      "Number of features = 784\n"
     ]
    }
   ],
   "source": [
    "num_features = np.shape(X)[1]*np.shape(X)[2]\n",
    "X = X.reshape(np.shape(X)[0], 784)\n",
    "X_test = X_test.reshape(np.shape(X_test)[0], 784)\n",
    "X_train, Xv, Y_train, Yv = sklearn.model_selection.train_test_split(\n",
    "    X, Y, test_size=0.1, random_state=4, shuffle=True)\n",
    "print(\"Size of Training DataSet =\", len(X_train))\n",
    "print(\"Size of Validation DataSet =\", len(Xv))\n",
    "print(\"Size of Test DataSet =\", len(X_test))\n",
    "print(\"Number of classes =\", num_classes)\n",
    "print(\"Number of features =\", num_features)\n",
    "X_train = X_train.T\n",
    "Xv = Xv.T\n",
    "X_test = X_test.T\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1. /(1. + np.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def der_sigmoid(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "def der_tanh(x):\n",
    "    return 1-(np.tanh(x)**2)\n",
    "\n",
    "def der_relu(x):\n",
    "    return (x>0)*1\n",
    "\n",
    "def softmax(x):\n",
    "    return (np.exp(x)/np.sum(np.exp(x),axis = 0))\n",
    "\n",
    "def der_softmax(x):\n",
    "    return softmax(x) * (1-softmax(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation and Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        # self.weight_initializers = {\"random\": self.random_initialization, \"xavier\": self.xavier_intialization}\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def ForwardPropagation(self,X):\n",
    "        W = self.W\n",
    "        b = self.b\n",
    "        A = [None]*len(W)\n",
    "        H = [None]*len(b)\n",
    "        for i in range(len(W)):\n",
    "            if i == 0:\n",
    "                A[i] = b[i] + W[i]@X\n",
    "            else:\n",
    "                A[i] = b[i] + W[i]@H[i-1]\n",
    "            if i == len(W) - 1:\n",
    "                H[i] = self.output_activation(A[i])\n",
    "            else:\n",
    "                H[i] = self.activation(A[i])\n",
    "        self.A = A\n",
    "        self.H = H\n",
    "    \n",
    "    def BackPropagation(self,X,Y):\n",
    "        W = self.W\n",
    "        b = self.b\n",
    "        A = self.A\n",
    "        H = self.H\n",
    "        grad_a = [None]*len(A)\n",
    "        grad_h = [None]*len(H)\n",
    "        grad_w = [None]*len(W)\n",
    "        grad_b = [None]*len(b)\n",
    "        N = len(W)\n",
    "        Y_hat = H[len(H)-1]\n",
    "        grad_a[N-1] = Y_hat - Y\n",
    "        \n",
    "        for i in range(N-1,-1,-1):\n",
    "            if i == 0:\n",
    "                grad_w[i] = grad_a[i]@X.T\n",
    "            else:\n",
    "                grad_w[i] = grad_a[i]@H[i-1].T\n",
    "            grad_b[i] = np.sum(grad_a[i],axis=1,keepdims=True)\n",
    "            if i>0 :\n",
    "                grad_h[i-1] = W[i].T@grad_a[i]\n",
    "                grad_a[i-1] = grad_h[i-1]*self.der_activation(A[i-1])\n",
    "        for i in range(N):\n",
    "            W[i] += self.weight_decay*W[i]   \n",
    "        self.grad_w = grad_w\n",
    "        self.grad_b = grad_b\n",
    "        self.W = W\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sgd:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def update_sgd_params(self,eta):\n",
    "        grad_w = self.params.grad_w\n",
    "        grad_b = self.params.grad_b\n",
    "        W = self.params.W\n",
    "        b = self.params.b\n",
    "        N = len(W)\n",
    "        for i in range(N):\n",
    "            W[i] = W[i] - eta*grad_w[i]\n",
    "            b[i] = b[i] - eta*grad_b[i]\n",
    "        \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum Based Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class momentum():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def updade_momentum_params(self,eta,beta):\n",
    "        grad_w = self.params.grad_w\n",
    "        grad_b = self.params.grad_b\n",
    "        W = self.params.W\n",
    "        b = self.params.b\n",
    "        u_W = self.u_params.W\n",
    "        u_b = self.u_params.b\n",
    "        N = len(grad_w)\n",
    "        for i in range(N):\n",
    "            u_W[i] = beta*u_W[i] + grad_w[i]\n",
    "            u_b[i] = beta*u_b[i] + grad_b[i]\n",
    "            W[i] = W[i] - eta*u_W[i]\n",
    "            b[i] = b[i] - eta*u_b[i]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nesterov Accelerated Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nesterov():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def update_nesterov_params(self,eta,beta,X,Y):\n",
    "        W = self.params.W\n",
    "        b = self.params.b\n",
    "        u_W = self.u_params.W\n",
    "        u_b = self.u_params.b\n",
    "        g_W = self.lookahead_params.W\n",
    "        g_b = self.lookahead_params.b\n",
    "        N = len(W)\n",
    "        for i in range(N):\n",
    "            g_W[i] = W[i] - beta*u_W[i]\n",
    "            g_b[i] = b[i] - beta*u_b[i]\n",
    "        self.lookahead_params.ForwardPropagation(X)\n",
    "        self.lookahead_params.BackPropagation(X,Y)\n",
    "        grad_w = self.lookahead_params.grad_w\n",
    "        grad_b = self.lookahead_params.grad_b\n",
    "        for i in range(N):\n",
    "            u_W[i] = beta*u_W[i] + grad_w[i]\n",
    "            u_b[i] = beta*u_b[i] + grad_b[i]\n",
    "            W[i] = W[i] - eta*u_W[i]\n",
    "            b[i] = b[i] - eta*u_b[i]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rmsprop():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def update_rmsprop_params(self,eta,beta,epsilon):\n",
    "        grad_w = self.params.grad_w\n",
    "        grad_b = self.params.grad_b\n",
    "        W = self.params.W\n",
    "        b = self.params.b\n",
    "        u_W = self.u_params.W\n",
    "        u_b = self.u_params.b\n",
    "        N = len(W)\n",
    "        for i in range(N):\n",
    "            u_W[i] = beta*u_W[i] + (1-beta)*np.multiply(grad_w[i],grad_w[i])\n",
    "            u_b[i] = beta*u_b[i] + (1-beta)*np.multiply(grad_b[i],grad_b[i])\n",
    "            W[i] = W[i] - (eta*grad_w[i]/(np.sqrt(u_W[i]+epsilon)))\n",
    "            b[i] = b[i] - (eta*grad_b[i]/(np.sqrt(u_b[i]+epsilon)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class adam():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def update_adam_params(self,eta,beta1,beta2,epsilon):\n",
    "        grad_w = self.params.grad_w\n",
    "        grad_b = self.params.grad_b\n",
    "        W = self.params.W\n",
    "        b = self.params.b\n",
    "        u_W = self.u_params.W\n",
    "        u_b = self.u_params.b\n",
    "        m_W = self.m_params.W\n",
    "        m_b = self.m_params.b\n",
    "        N = len(W)\n",
    "        for i in range(N):\n",
    "            m_W[i] = beta1*m_W[i] + (1-beta1)*grad_w[i]\n",
    "            m_b[i] = beta1*m_b[i] + (1-beta1)*grad_b[i]\n",
    "            u_W[i] = beta2*u_W[i] + (1-beta2)*np.multiply(grad_w[i],grad_w[i])\n",
    "            u_b[i] = beta2*u_b[i] + (1-beta2)*np.multiply(grad_b[i],grad_b[i])\n",
    "            \n",
    "            m_hat_W = m_W[i]/(1-np.power(beta1,i+1))\n",
    "            m_hat_b = m_b[i]/(1-np.power(beta1,i+1))\n",
    "            u_hat_W = u_W[i]/(1-np.power(beta2,i+1))\n",
    "            u_hat_b = u_b[i]/(1-np.power(beta2,i+1))\n",
    "            \n",
    "            W[i] = W[i] - (eta*m_hat_W/(np.sqrt(u_hat_W)+epsilon))\n",
    "            b[i] = b[i] - (eta*m_hat_b/(np.sqrt(u_hat_b)+epsilon))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nadam():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def update_nadam_params(self,eta,beta,beta1,beta2,epsilon,X,Y):\n",
    "        W = self.params.W\n",
    "        b = self.params.b\n",
    "        u_W = self.u_params.W\n",
    "        u_b = self.u_params.b\n",
    "        m_W = self.m_params.W\n",
    "        m_b = self.m_params.b\n",
    "        g_W = self.lookahead_params.W\n",
    "        g_b = self.lookahead_params.b\n",
    "        N = len(W)\n",
    "        for i in range(N):\n",
    "            g_W[i] = W[i] - beta*u_W[i]\n",
    "            g_b[i] = b[i] - beta*u_b[i]\n",
    "        self.lookahead_params.ForwardPropagation(X)\n",
    "        self.lookahead_params.BackPropagation(X,Y)\n",
    "        grad_w = self.lookahead_params.grad_w\n",
    "        grad_b = self.lookahead_params.grad_b\n",
    "        for i in range(N):\n",
    "            m_W[i] = beta1*m_W[i] + (1-beta1)*grad_w[i]\n",
    "            m_b[i] = beta1*m_b[i] + (1-beta1)*grad_b[i]\n",
    "            u_W[i] = beta2*u_W[i] + (1-beta2)*np.multiply(grad_w[i],grad_w[i])\n",
    "            u_b[i] = beta2*u_b[i] + (1-beta2)*np.multiply(grad_b[i],grad_b[i])\n",
    "            \n",
    "            m_hat_W = m_W[i]/(1-np.power(beta1,i+1))\n",
    "            m_hat_b = m_b[i]/(1-np.power(beta1,i+1))\n",
    "            u_hat_W = u_W[i]/(1-np.power(beta2,i+1))\n",
    "            u_hat_b = u_b[i]/(1-np.power(beta2,i+1))\n",
    "            \n",
    "            W[i] = W[i] - (eta*m_hat_W/(np.sqrt(u_hat_W)+epsilon))\n",
    "            b[i] = b[i] - (eta*m_hat_b/(np.sqrt(u_hat_b)+epsilon))\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Your optimizer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class optimizer_name():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def update_op_params(self,):\n",
    "        '''\n",
    "        Add your code to update parameters\n",
    "        '''\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    '''\n",
    "        weight_initializers : dictionary with random , xavier\n",
    "        weight_initializer : function\n",
    "        activation_funtions : dictionary with sigmoid, tanh, relu\n",
    "        der_activation_functions : dictionary with derivatives of the above\n",
    "        optimizer_funtions : dictionary with sgd, momentum, nesterov, rmsprop, adam, nadam}\n",
    "        activation : string\n",
    "        opitmizer : string\n",
    "        learning_rate : int\n",
    "        batch_size : int\n",
    "        num_epochs : int\n",
    "        num_features : dimension of X\n",
    "        num_hidden_layers : int, number of hidden layers\n",
    "        output_layer_dim : int\n",
    "        hidden_layer_dims : np.array with num_neurons in all hidden layer \n",
    "        weight_Decay : \n",
    "        X_train : Training Data (n,d)\n",
    "        Y_train : Training Data (n,)\n",
    "        Xv : Validation Data (n,d)\n",
    "        Yv : Validation Data (n,)\n",
    "        hidden_layers : np.array of objects to class hidden_layer dimensions = num_hidden_layers\n",
    "        output_layer : object to hidden_layer class\n",
    "        beta : momentum\n",
    "        beta1 : adam\n",
    "        beta2 : adam\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 num_features,\n",
    "                 weight_initializer,\n",
    "                 num_hidden_layers,\n",
    "                 hidden_layer_dims,\n",
    "                 optimizer,\n",
    "                 learning_rate,\n",
    "                 activation,\n",
    "                 X_train,\n",
    "                 Y_train,\n",
    "                 Xv,\n",
    "                 Yv,\n",
    "                 weight_decay,\n",
    "                 output_layer_dim,\n",
    "                 batch_size,\n",
    "                 num_epochs,\n",
    "                 output_activation = softmax,\n",
    "                 der_output_activation = der_softmax,\n",
    "                 beta=0.9,\n",
    "                 epsilon=1e-6,\n",
    "                 beta1=0.9,\n",
    "                 beta2=0.999):\n",
    "        self.weight_initializers = {\"random\": self.random_initialization, \"xavier\": self.xavier_intialization}\n",
    "        self.weight_initializer = self.weight_initializers[weight_initializer]\n",
    "        self.activation_functions = {\"sigmoid\": sigmoid, \"tanh\": tanh, \"ReLU\": relu}\n",
    "        self.der_activation_functions = {\"sigmoid\": der_sigmoid, \"tanh\": der_tanh, \"ReLU\": der_relu}\n",
    "        '''\n",
    "            Add your optimizer function and class in the below dictionaries\n",
    "        '''\n",
    "        self.optimizer_functions = {\"sgd\": self.sgd, \"momentum\": self.momentum,\"nesterov\": self.nesterov, \"rmsprop\": self.rmsprop, \"adam\": self.adam, \"nadam\": self.nadam}\n",
    "        self.optimizer_classes = {\"sgd\": sgd, \"momentum\": momentum,\"nesterov\": nesterov, \"rmsprop\": rmsprop, \"adam\": adam, \"nadam\": nadam}\n",
    "        self.activation = self.activation_functions[activation]\n",
    "        self.optimizer = self.optimizer_functions[optimizer]\n",
    "        self.optimizer_class = self.optimizer_classes[optimizer]\n",
    "        self.der_activation = self.der_activation_functions[activation]\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.output_layer_dim = output_layer_dim\n",
    "        self.hidden_layer_dims = hidden_layer_dims\n",
    "        self.num_features = num_features\n",
    "        self.output_activation = output_activation\n",
    "        self.der_output_activation = der_output_activation\n",
    "        self.weight_decay = weight_decay\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.Xv = Xv\n",
    "        self.Yv = Yv\n",
    "        self.beta = beta\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.num_classes = self.output_layer_dim\n",
    "        # return self\n",
    "        \n",
    "    def Square_Error_Loss(self,Y_pred,Y_actual):\n",
    "        return np.mean((Y_pred-Y_actual)**2)\n",
    "    \n",
    "    def Cross_Entropy_Loss(self,Y_pred,Y_actual):\n",
    "        return -np.sum(Y_actual*np.log(Y_pred))/float(Y_pred.shape[0])\n",
    "    \n",
    "    def random_initialization(self, in_layer, out_layer):\n",
    "        return np.random.randn(in_layer, out_layer)\n",
    "\n",
    "    def xavier_intialization(self, in_layer, out_layer):\n",
    "        return np.random.randn(in_layer, out_layer)* np.sqrt(2 / (in_layer + out_layer))\n",
    "    \n",
    "    def sgd(self,X,Y):\n",
    "        sgd_obj = self.optimizer_object\n",
    "        parameters = self.params\n",
    "        parameters.ForwardPropagation(X)\n",
    "        parameters.BackPropagation(X,Y)\n",
    "        sgd_obj.update_sgd_params(self.learning_rate)\n",
    "    \n",
    "    def momentum(self,X,Y):\n",
    "        momentum_obj = self.optimizer_object\n",
    "        parameters = self.params\n",
    "        parameters.ForwardPropagation(X)\n",
    "        parameters.BackPropagation(X,Y)\n",
    "        momentum_obj.updade_momentum_params(self.learning_rate,self.beta)\n",
    "\n",
    "    def nesterov(self,X,Y):\n",
    "        nesterov_obj = self.optimizer_object\n",
    "        nesterov_obj.update_nesterov_params(self.learning_rate,self.beta,X,Y)\n",
    "    \n",
    "    def rmsprop(self,X,Y):\n",
    "        rmsprop_obj = self.optimizer_object\n",
    "        parameters = self.params\n",
    "        parameters.ForwardPropagation(X)\n",
    "        parameters.BackPropagation(X,Y)\n",
    "        rmsprop_obj.update_rmsprop_params(self.learning_rate,self.beta,self.epsilon)\n",
    "    \n",
    "    def adam(self,X,Y):\n",
    "        adam_obj = self.optimizer_object\n",
    "        parameters = self.params\n",
    "        parameters.ForwardPropagation(X)\n",
    "        parameters.BackPropagation(X,Y)\n",
    "        adam_obj.update_adam_params(self.learning_rate,self.beta1,self.beta2,self.epsilon)\n",
    "    \n",
    "    def nadam(self,X,Y):\n",
    "        nadam_obj = self.optimizer_object\n",
    "        nadam_obj.update_nadam_params(self.learning_rate,self.beta,self.beta1,self.beta2,self.epsilon,X,Y)\n",
    "    \n",
    "    def optimzizer_name(self,X,Y):\n",
    "        '''\n",
    "            May implement forward and backpropagation here \n",
    "            Add code to create an object to your optimizer class\n",
    "            Then use this object to call your optimizer_update method \n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def sanitize_Y(self):\n",
    "            \n",
    "        temp = np.zeros((num_classes,self.Y_train.shape[0]))\n",
    "        for i in range(self.Y_train.shape[0]) :\n",
    "            temp[int(self.Y_train[i])][i] = 1\n",
    "        self.Y_train = temp\n",
    "        \n",
    "        temp = np.zeros((num_classes,self.Yv.shape[0]))\n",
    "        for i in range(self.Yv.shape[0]) :\n",
    "            temp[int(self.Yv[i])][i] = 1\n",
    "        self.Yv = temp\n",
    "        \n",
    "    def initialize_NeuralNet(self):\n",
    "        self.sanitize_Y()\n",
    "        self.optimizer_object = self.optimizer_class()\n",
    "        self.params = self.initialize_parameters()\n",
    "        self.optimizer_object.params = self.params\n",
    "        self.optimizer_object.u_params = self.initialize_parameters()\n",
    "        self.optimizer_object.m_params = self.initialize_parameters()\n",
    "        self.optimizer_object.lookahead_params = self.initialize_parameters()\n",
    "        '''\n",
    "            can add required optimizer params and \n",
    "            initialize the here \n",
    "        '''\n",
    "        # pass\n",
    "    \n",
    "    def add_hidden(self,num_neurons):\n",
    "        self.hidden_layer_dims.append(num_neurons)\n",
    "        self.num_hidden_layers += 1\n",
    "        # pass\n",
    "    \n",
    "    def initialize_parameters(self):\n",
    "        params = Parameters()\n",
    "        W = []\n",
    "        b = []\n",
    "        in_layer, out_layer = num_features,self.hidden_layer_dims[1]\n",
    "        for i in range(self.num_hidden_layers):\n",
    "            if  i == 0:\n",
    "                in_layer = num_features\n",
    "            else:\n",
    "                in_layer = self.hidden_layer_dims[i-1]\n",
    "                \n",
    "            if i == self.num_hidden_layers-1:\n",
    "                out_layer = self.output_layer_dim\n",
    "            else:\n",
    "                out_layer = self.hidden_layer_dims[i+1]\n",
    "            W.append(self.weight_initializer(self.hidden_layer_dims[i],in_layer))\n",
    "            b.append(np.zeros(shape=(self.hidden_layer_dims[i],1)))\n",
    "        W.append(self.weight_initializer(self.num_classes,self.hidden_layer_dims[self.num_hidden_layers-1]))\n",
    "        b.append(np.zeros(shape=(self.num_classes,1)))\n",
    "        params.W = W\n",
    "        params.b = b\n",
    "        params.activation = self.activation\n",
    "        params.output_activation = self.output_activation\n",
    "        params.der_activation = self.der_activation\n",
    "        params.weight_decay = self.weight_decay\n",
    "        return params\n",
    "    \n",
    "    def fit_NeuralNet(self):\n",
    "        self.initialize_NeuralNet()\n",
    "        for curr_epoch in range(self.num_epochs):\n",
    "            print(\"Epoch Number : \",curr_epoch+1)  \n",
    "            for i in range(0,self.X_train.shape[1],self.batch_size):\n",
    "                curr_batch = min(self.X_train.shape[1]-i,self.batch_size)\n",
    "                self.optimizer(self.X_train[:,i:i+curr_batch],self.Y_train[:,i:i+curr_batch])\n",
    "                # print(self.params.W)\n",
    "                # print(self.params.b)\n",
    "            # Y_pred = self.predict_NeuralNet(self.X_train)\n",
    "            # print(\"Cross Entropy Loss in the\",curr_epoch+1,\"epoch :\",self.Cross_Entropy_Loss(Y_pred, Y_train))\n",
    "        # pass\n",
    "    \n",
    "    def predict_NeuralNet(self,X):\n",
    "        self.params.ForwardPropagation(X)\n",
    "        Y_pred = np.argmax(self.params.H[len(self.params.H)-1],axis=0)\n",
    "        return Y_pred\n",
    "    \n",
    "    def accuracy_NeuralNet(self,X_train,Y_Train,X_test,Y_test):\n",
    "        Y_train_pred = self.predict_NeuralNet(X_train)\n",
    "        Y_test_pred = self.predict_NeuralNet(X_test)\n",
    "        print(\"Training Accuracy =\",accuracy_score(self.Y_train_pred,Y_train)*100)\n",
    "        print(\"Test Accuracy =\",accuracy_score(self.Y_test_pred,Y_test)*100)\n",
    "        \n",
    "    def print_all(self):\n",
    "        # print(\"weight_initializer = \",self.weight_initializer)\n",
    "        # print(\"activation_functions = \",self.activation_functions)\n",
    "        # print(\"optimizer_functions = \",self.optimizer_functions)\n",
    "        # print(\"weight_initializers = \",self.weight_initializers)\n",
    "        # print(\"activation = \",self.activation)\n",
    "        # print(\"optimizer = \",self.optimizer)\n",
    "        # print(\"learning_rate = \",self.learning_rate)\n",
    "        # print(\"batch_size = \",self.batch_size)\n",
    "        # print(\"num_epochs = \",self.num_epochs)\n",
    "        # print(\"num_hidden_layers = \",self.num_hidden_layers)\n",
    "        # print(\"output_layer_dim = \",self.output_layer_dim)\n",
    "        # print(\"hidden_layer_dims = \",self.hidden_layer_dims)\n",
    "        # print(\"num_features = \",self.num_features)\n",
    "        # print(\"weight_Decay = \",self.weight_Decay)\n",
    "        # print(\"X_train = \",self.X_train)\n",
    "        # print(\"Y_train = \",self.Y_train)\n",
    "        # print(\"Xv = \",self.Xv)\n",
    "        # print(\"Yv = \",self.Yv)\n",
    "        # print(self.output_layer.h)\n",
    "        # print(self.num_hidden_layers)\n",
    "        \n",
    "        L = self.hidden_layers\n",
    "        for i in range(self.num_hidden_layers):\n",
    "            \n",
    "            # print(i)\n",
    "            # print(i,\" \",self.hidden_layers[i].dim_in_layer,self.hidden_layers[i].num_neurons,self.hidden_layers[i].dim_out_layer,self.hidden_layers[i].W.shape,self.hidden_layers[i].b.shape)\n",
    "            # print(self.hidden_layers[i].W)\n",
    "            # print(self.hidden_layers[i].b)\n",
    "            # print(L[i].W.shape,L[i].grad_W.shape,L[i].u_mgd_W.shape,L[i].m_W.shape)\n",
    "            # print(L[i].grad_a.shape)\n",
    "            print(L[i].W)\n",
    "            print(L[i].b)\n",
    "            print(L[i].grad_W)\n",
    "            print(L[i].grad_b)\n",
    "        print(self.output_layer.W)\n",
    "        print(self.output_layer.b)\n",
    "        print(self.output_layer.grad_W)\n",
    "        print(self.output_layer.grad_b)\n",
    "        \n",
    "        print()\n",
    "        # print(self.output_layer.W.shape,self.output_layer.grad_W.shape)\n",
    "        # print(self.output_layer.grad_a.shape)\n",
    "        # print(\"output-layer\")\n",
    "        # print(self.output_layer.W.shape)\n",
    "        # print(\"o  \",self.output_layer.num_neurons,self.output_layer.dim_in_layer,self.output_layer.dim_out_layer)\n",
    "        # pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3466/2446329309.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1. /(1. + np.exp(-x))\n",
      "/tmp/ipykernel_3466/1606346498.py:89: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.sum(Y_actual*np.log(Y_pred))/float(Y_pred.shape[0])\n",
      "/tmp/ipykernel_3466/1606346498.py:89: RuntimeWarning: invalid value encountered in multiply\n",
      "  return -np.sum(Y_actual*np.log(Y_pred))/float(Y_pred.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy Loss in the 1 epoch : nan\n",
      "Cross Entropy Loss in the 1 epoch : nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3466/2446329309.py:20: RuntimeWarning: overflow encountered in exp\n",
      "  return (np.exp(x)/np.sum(np.exp(x),axis = 0))\n",
      "/tmp/ipykernel_3466/2446329309.py:20: RuntimeWarning: invalid value encountered in divide\n",
      "  return (np.exp(x)/np.sum(np.exp(x),axis = 0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy Loss in the 1 epoch : nan\n",
      "Cross Entropy Loss in the 1 epoch : nan\n",
      "Cross Entropy Loss in the 1 epoch : nan\n",
      "Cross Entropy Loss in the 1 epoch : nan\n",
      "Cross Entropy Loss in the 1 epoch : nan\n",
      "Cross Entropy Loss in the 1 epoch : nan\n",
      "Cross Entropy Loss in the 1 epoch : nan\n",
      "Cross Entropy Loss in the 1 epoch : nan\n",
      "Cross Entropy Loss in the 1 epoch : nan\n",
      "Cross Entropy Loss in the 1 epoch : nan\n",
      "Cross Entropy Loss in the 1 epoch : nan\n",
      "Cross Entropy Loss in the 1 epoch : nan\n",
      "Cross Entropy Loss in the 1 epoch : nan\n",
      "Cross Entropy Loss in the 1 epoch : nan\n",
      "Cross Entropy Loss in the 1 epoch : nan\n",
      "Cross Entropy Loss in the 1 epoch : nan\n",
      "Cross Entropy Loss in the 1 epoch : nan\n",
      "Cross Entropy Loss in the 1 epoch : nan\n",
      "Cross Entropy Loss in the 1 epoch : nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 37\u001b[0m\n\u001b[1;32m     14\u001b[0m N \u001b[39m=\u001b[39m NeuralNet(num_features \u001b[39m=\u001b[39m NUM_FEATURES,\n\u001b[1;32m     15\u001b[0m                 weight_initializer \u001b[39m=\u001b[39m WEIGHT_INITIALIZER,\n\u001b[1;32m     16\u001b[0m                 num_hidden_layers \u001b[39m=\u001b[39m NUM_HIDDEN_LAYERS,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 batch_size \u001b[39m=\u001b[39m BATCH_SIZE,\n\u001b[1;32m     28\u001b[0m                 num_epochs \u001b[39m=\u001b[39m EPOCHS)\n\u001b[1;32m     30\u001b[0m \u001b[39m# N.initialize_hidden_layers()\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m# N.initialize_NeuralNet()\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m# N.ForwardPropagation(N.X_train[:,0:500])\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39m# N.BackPropagation(N.output_layer.h,N.Y_train[:,0:500],N.X_train[:,0:500])\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39m# N.print_all()\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m N\u001b[39m.\u001b[39mfit_NeuralNet()\n",
      "Cell \u001b[0;32mIn[114], line 208\u001b[0m, in \u001b[0;36mNeuralNet.fit_NeuralNet\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_train[:,i:i\u001b[39m+\u001b[39mcurr_batch],\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mY_train[:,i:i\u001b[39m+\u001b[39mcurr_batch])\n\u001b[1;32m    206\u001b[0m \u001b[39m# print(self.params.W)\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m# print(self.params.b)\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m Y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_NeuralNet(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX_train)\n\u001b[1;32m    209\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCross Entropy Loss in the\u001b[39m\u001b[39m\"\u001b[39m,curr_epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mepoch :\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mCross_Entropy_Loss(Y_pred, Y_train))\n",
      "Cell \u001b[0;32mIn[114], line 215\u001b[0m, in \u001b[0;36mNeuralNet.predict_NeuralNet\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_NeuralNet\u001b[39m(\u001b[39mself\u001b[39m,X):\n\u001b[0;32m--> 215\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams\u001b[39m.\u001b[39;49mForwardPropagation(X)\n\u001b[1;32m    216\u001b[0m     Y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mH[\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mH)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    217\u001b[0m     \u001b[39mreturn\u001b[39;00m Y_pred\n",
      "Cell \u001b[0;32mIn[106], line 20\u001b[0m, in \u001b[0;36mParameters.ForwardPropagation\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     18\u001b[0m         H[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_activation(A[i])\n\u001b[1;32m     19\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m         H[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactivation(A[i])\n\u001b[1;32m     21\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mA \u001b[39m=\u001b[39m A\n\u001b[1;32m     22\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mH \u001b[39m=\u001b[39m H\n",
      "Cell \u001b[0;32mIn[105], line 2\u001b[0m, in \u001b[0;36msigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msigmoid\u001b[39m(x):\n\u001b[0;32m----> 2\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m1.\u001b[39m \u001b[39m/\u001b[39m(\u001b[39m1.\u001b[39m \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39;49mexp(\u001b[39m-\u001b[39;49mx))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_FEATURES = X_train.shape[0]\n",
    "WEIGHT_INITIALIZER = \"random\"\n",
    "NUM_HIDDEN_LAYERS = 3\n",
    "# HIDDEN_LAYER_DIMS = (128+np.arange(NUM_HIDDEN_LAYERS)).astype(int)\n",
    "HIDDEN_LAYER_DIMS = (128+np.zeros(NUM_HIDDEN_LAYERS)).astype(int)\n",
    "OPTIMIZER = \"nesterov\"\n",
    "LEARNING_RATE = 0.001\n",
    "ACTIVATION = \"sigmoid\"\n",
    "OUTPUT_LAYER_DIM = num_classes\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 1\n",
    "WEIGHT_DECAY = 0\n",
    "\n",
    "N = NeuralNet(num_features = NUM_FEATURES,\n",
    "                weight_initializer = WEIGHT_INITIALIZER,\n",
    "                num_hidden_layers = NUM_HIDDEN_LAYERS,\n",
    "                hidden_layer_dims = HIDDEN_LAYER_DIMS,\n",
    "                optimizer = OPTIMIZER,\n",
    "                learning_rate = LEARNING_RATE,\n",
    "                activation = ACTIVATION,\n",
    "                X_train = X_train,\n",
    "                Y_train = Y_train,\n",
    "                Xv = Xv,\n",
    "                Yv = Yv,\n",
    "                weight_decay=WEIGHT_DECAY,\n",
    "                output_layer_dim = OUTPUT_LAYER_DIM,\n",
    "                batch_size = BATCH_SIZE,\n",
    "                num_epochs = EPOCHS)\n",
    "\n",
    "# N.initialize_hidden_layers()\n",
    "# N.initialize_NeuralNet()\n",
    "# N.ForwardPropagation(N.X_train[:,0:500])\n",
    "# print(N.Y_train[:,0:500].shape)\n",
    "# print(N.output_layer.h.shape)\n",
    "# N.BackPropagation(N.output_layer.h,N.Y_train[:,0:500],N.X_train[:,0:500])\n",
    "# N.print_all()\n",
    "N.fit_NeuralNet()\n",
    "# N.print_all()\n",
    "# print(X_train.shape)\n",
    "# for i in range(X_train.shape[0]):\n",
    "#     N.ForwardPropagation(X_train[i])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0997962962962963\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Y_pred_train = N.predict_NeuralNet(N.X_train)\n",
    "# print(accuracy_score(y_pred=Y_pred_train,y_true=Y_train))\n",
    "# for i in Y_pred_train:\n",
    "#     print(i)\n",
    "# for i in Y_pred_train:\n",
    "#     print(i)\n",
    "# print(Y_pred_train)\n",
    "print(accuracy_score(y_pred=Y_pred_train,y_true=Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__():\n",
    "        pass\n",
    "\n",
    "class B:\n",
    "    def __init__():\n",
    "        pass\n",
    "\n",
    "class C:\n",
    "    def __init__():\n",
    "        pass\n",
    "C.x = 5\n",
    "A.x = C\n",
    "B.x = C\n",
    "A.x.x = 6\n",
    "print(B.x.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sweep_config = {\n",
    "#     \"name\" : \"GridSearch\",\n",
    "#     \"method\" : \"\",\n",
    "#     \"metric\" :{\n",
    "#         \"name\" : \"validationaccuracy\",\n",
    "#         \"goal\" : \"maximize\"\n",
    "#     },\n",
    "#     \"parameters\" : {\n",
    "#         \"num_epochs\" : {\n",
    "#             \"values\" : [5,10]\n",
    "#         },\n",
    "#         \"num_hidden_layers\" : {\n",
    "#             \"values\" : [ 3, 4, 5]\n",
    "#         },\n",
    "#         \"size_hidden_layer\" : {\n",
    "#             \"values\" : [32, 64, 128]\n",
    "#         },\n",
    "#         \"weight_decay\" : {\n",
    "#             \"values\" : [0, 0.0005, 0.5]\n",
    "#         },\n",
    "#         \"learning_rate\" : {\n",
    "#             \"values\" : [0.001,0.0001]\n",
    "#         },\n",
    "#         \"optimizer\" : {\n",
    "#            \"values\" : [\"sgd\", \"momentum\", \"nesterov\", \"rmsprop\", \"adam\", \"nadam\"] \n",
    "#         },\n",
    "#         \"batch_size\" : {\n",
    "#             \"values\" : [16, 32, 64]\n",
    "#         },\n",
    "#         \"weight_initializer\" : {\n",
    "#             \"values\" : [\"random\",\"xavier\"]\n",
    "#         },\n",
    "#         \"activation\" : {\n",
    "#             \"values\" : [\"sigmoid\", \"tanh\", \"ReLU\"]\n",
    "#         },\n",
    "#     }\n",
    "# }\n",
    "# sweep_id = wandb.sweep(sweep_config,project=\"CS6910_Assignment_1\",entity=\"Arunesh J B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train():\n",
    "#     config_defaults = {\n",
    "#         \"num_epochs\" : 10,\n",
    "#         \"batch_size\" : 64,\n",
    "#         \"learning_rate\" : 0.001,\n",
    "#         \"activation\" : \"ReLU\",\n",
    "#         \"optimizer\" : \"adam\",\n",
    "#         \"weight_intializer\" : \"xavier\",\n",
    "#         \"weight_decay\" : 0,\n",
    "#         \"hidden_layer_size\" : 64,\n",
    "#         \"num_hidden_layers\" : 3,\n",
    "#     }\n",
    "    \n",
    "#     wandb.init(config=config_defaults)\n",
    "#     config = wandb.config\n",
    "#     HIDDEN_LAYER_SIZE = config.hidden_layer_size\n",
    "#     NUM_FEATURES = X_train.shape[0]\n",
    "#     WEIGHT_INITIALIZER = config.weight_intializer\n",
    "#     NUM_HIDDEN_LAYERS = config.num_hidden_layers\n",
    "#     HIDDEN_LAYER_DIMS = (config.hidden_layer_size+np.zeros(NUM_HIDDEN_LAYERS)).astype(int)\n",
    "#     OPTIMIZER = config.optimizer\n",
    "#     LEARNING_RATE = config.learning_rate\n",
    "#     ACTIVATION = config.activation\n",
    "#     OUTPUT_LAYER_DIM = num_classes\n",
    "#     BATCH_SIZE = config.batch_size\n",
    "#     EPOCHS = config.num_epochs\n",
    "#     WEIGHT_DECAY = config.weight_decay\n",
    "    \n",
    "#     run_name = \"op_{}_ac_{}_wi_{}_lr_{}_bs_{}_l2_{}_nh_{}_sh_{}_ep_{}\".format(OPTIMIZER,ACTIVATION,WEIGHT_INITIALIZER,LEARNING_RATE,BATCH_SIZE,WEIGHT_DECAY,NUM_HIDDEN_LAYERS,HIDDEN_LAYER_SIZE,EPOCHS)\n",
    "    \n",
    "#     FFN = NeuralNet(num_features = NUM_FEATURES,\n",
    "#                     weight_initializer = WEIGHT_INITIALIZER,\n",
    "#                     num_hidden_layers = NUM_HIDDEN_LAYERS,\n",
    "#                     hidden_layer_dims = HIDDEN_LAYER_DIMS,\n",
    "#                     optimizer = OPTIMIZER,\n",
    "#                     learning_rate = LEARNING_RATE,\n",
    "#                     activation = ACTIVATION,\n",
    "#                     X_train = X_train,\n",
    "#                     Y_train = Y_train,\n",
    "#                     Xv = Xv,\n",
    "#                     Yv = Yv,\n",
    "#                     weight_decay=WEIGHT_DECAY,\n",
    "#                     output_layer_dim = OUTPUT_LAYER_DIM,\n",
    "#                     batch_size = BATCH_SIZE,\n",
    "#                     num_epochs = EPOCHS)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
