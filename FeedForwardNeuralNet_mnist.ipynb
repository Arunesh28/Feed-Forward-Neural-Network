{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px; text-align:center\">CS6910 - Assignment 1</p>\n",
    "<!-- <p style=\"font-size:18px; text-align:center\">CS6910: Fundamentals of Deep Learning</p> -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px; text-align:\">Arunesh J B (CS20B009)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "import wandb\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion Mnist Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, Y), (X_test, Y_test) = mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_classes = len(np.unique(Y))\n",
    "unique_classes = [X[np.where(Y == i)[0][0]] for i in range(num_classes)]\n",
    "class_names = [\"T-shirt\", \"Trouser\", \"Pullover\", \"Dress\",\n",
    "               \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "images = []\n",
    "classes = []\n",
    "for i in range(1, num_classes+1):\n",
    "    plt.subplot(2, 5, i)\n",
    "    plt.imshow(unique_classes[i-1])\n",
    "    plt.title(class_names[i-1], fontdict={'fontsize': 7})\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Training DataSet = 54000\n",
      "Size of Validation DataSet = 6000\n",
      "Size of Test DataSet = 10000\n",
      "Number of classes = 10\n",
      "Number of features = 784\n"
     ]
    }
   ],
   "source": [
    "num_features = np.shape(X)[1]*np.shape(X)[2]\n",
    "X = X/255.0\n",
    "X_test = X_test/255.0\n",
    "X = X.reshape(np.shape(X)[0], 784)\n",
    "X_test = X_test.reshape(np.shape(X_test)[0], 784)\n",
    "X_train, Xv, Y_train, Yv = sklearn.model_selection.train_test_split(\n",
    "    X, Y, test_size=0.1, random_state=4, shuffle=True)\n",
    "print(\"Size of Training DataSet =\", len(X_train))\n",
    "print(\"Size of Validation DataSet =\", len(Xv))\n",
    "print(\"Size of Test DataSet =\", len(X_test))\n",
    "print(\"Number of classes =\", num_classes)\n",
    "print(\"Number of features =\", num_features)\n",
    "X_train = X_train.T\n",
    "Xv = Xv.T\n",
    "X_test = X_test.T\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1. /(1. + np.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def der_sigmoid(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "def der_tanh(x):\n",
    "    return 1-(np.tanh(x)**2)\n",
    "\n",
    "def der_relu(x):\n",
    "    return (x>0)*1\n",
    "\n",
    "def softmax(x):\n",
    "    \n",
    "    return (np.exp(x)/np.sum(np.exp(x),axis = 0))\n",
    "\n",
    "def der_softmax(x):\n",
    "    return softmax(x) * (1-softmax(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation and Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def ForwardPropagation(self,X):\n",
    "        W = self.W\n",
    "        b = self.b\n",
    "        A = [None]*len(W)\n",
    "        H = [None]*len(b)\n",
    "        for i in range(len(W)):\n",
    "            if i == 0:\n",
    "                A[i] = b[i] + W[i]@X\n",
    "            else:\n",
    "                A[i] = b[i] + W[i]@H[i-1]\n",
    "            if i == len(W) - 1:\n",
    "                H[i] = self.output_activation(A[i])\n",
    "            else:\n",
    "                H[i] = self.activation(A[i])\n",
    "        self.A = A\n",
    "        self.H = H\n",
    "    \n",
    "    def BackPropagation(self,X,Y):\n",
    "        W = self.W\n",
    "        b = self.b\n",
    "        A = self.A\n",
    "        H = self.H\n",
    "        grad_a = [None]*len(A)\n",
    "        grad_h = [None]*len(H)\n",
    "        grad_w = [None]*len(W)\n",
    "        grad_b = [None]*len(b)\n",
    "        N = len(W)\n",
    "        \n",
    "        Y_hat = H[len(H)-1]\n",
    "        grad_a[N-1] = Y_hat - Y\n",
    "        for i in range(N-1,-1,-1):\n",
    "            if i == 0:\n",
    "                grad_w[i] = grad_a[i]@X.T\n",
    "            else:\n",
    "                grad_w[i] = grad_a[i]@H[i-1].T\n",
    "            grad_b[i] = np.sum(grad_a[i],axis=1,keepdims=True)\n",
    "            if i>0 :\n",
    "                grad_h[i-1] = W[i].T@grad_a[i]\n",
    "                grad_a[i-1] = grad_h[i-1]*self.der_activation(A[i-1])\n",
    "        for i in range(N):\n",
    "            W[i] += self.weight_decay*W[i]   \n",
    "        self.grad_w = grad_w\n",
    "        self.grad_b = grad_b\n",
    "        self.W = W\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sgd:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def update_sgd_params(self,eta):\n",
    "        grad_w = self.params.grad_w\n",
    "        grad_b = self.params.grad_b\n",
    "        W = self.params.W\n",
    "        b = self.params.b\n",
    "        N = len(W)\n",
    "        for i in range(N):\n",
    "            W[i] = W[i] - eta*grad_w[i]\n",
    "            b[i] = b[i] - eta*grad_b[i]\n",
    "        \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum Based Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class momentum():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def updade_momentum_params(self,eta,beta):\n",
    "        grad_w = self.params.grad_w\n",
    "        grad_b = self.params.grad_b\n",
    "        W = self.params.W\n",
    "        b = self.params.b\n",
    "        u_W = self.u_params.W\n",
    "        u_b = self.u_params.b\n",
    "        N = len(grad_w)\n",
    "        for i in range(N):\n",
    "            u_W[i] = beta*u_W[i] + grad_w[i]\n",
    "            u_b[i] = beta*u_b[i] + grad_b[i]\n",
    "            W[i] = W[i] - eta*u_W[i]\n",
    "            b[i] = b[i] - eta*u_b[i]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nesterov Accelerated Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nesterov():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def update_nesterov_params(self,eta,beta,X,Y):\n",
    "        W = self.params.W\n",
    "        b = self.params.b\n",
    "        u_W = self.u_params.W\n",
    "        u_b = self.u_params.b\n",
    "        g_W = self.lookahead_params.W\n",
    "        g_b = self.lookahead_params.b\n",
    "        N = len(W)\n",
    "        \n",
    "        self.params.ForwardPropagation(X)\n",
    "        self.params.BackPropagation(X,Y)\n",
    "        \n",
    "        grad_w = self.params.grad_w\n",
    "        grad_b = self.params.grad_b\n",
    "        \n",
    "        for i in range(N):\n",
    "            g_W[i] = grad_w[i]\n",
    "            g_b[i] = grad_b[i]\n",
    "        \n",
    "        \n",
    "        for i in range(N):\n",
    "            u_W[i] = beta*u_W[i] + g_W[i]\n",
    "            u_b[i] = beta*u_b[i] + g_b[i]\n",
    "            W[i] = W[i] - eta*(beta*u_W[i] + g_W[i])\n",
    "            b[i] = b[i] - eta*(beta*u_b[i] + g_b[i])\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rmsprop():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def update_rmsprop_params(self,eta,beta,epsilon):\n",
    "        grad_w = self.params.grad_w\n",
    "        grad_b = self.params.grad_b\n",
    "        W = self.params.W\n",
    "        b = self.params.b\n",
    "        u_W = self.u_params.W\n",
    "        u_b = self.u_params.b\n",
    "        N = len(W)\n",
    "        for i in range(N):\n",
    "            u_W[i] = beta*u_W[i] + (1-beta)*np.multiply(grad_w[i],grad_w[i])\n",
    "            u_b[i] = beta*u_b[i] + (1-beta)*np.multiply(grad_b[i],grad_b[i])\n",
    "            W[i] = W[i] - (eta*grad_w[i]/(np.sqrt(u_W[i]+epsilon)))\n",
    "            b[i] = b[i] - (eta*grad_b[i]/(np.sqrt(u_b[i]+epsilon)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class adam():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def update_adam_params(self,eta,beta1,beta2,epsilon):\n",
    "        grad_w = self.params.grad_w\n",
    "        grad_b = self.params.grad_b\n",
    "        W = self.params.W\n",
    "        b = self.params.b\n",
    "        u_W = self.u_params.W\n",
    "        u_b = self.u_params.b\n",
    "        m_W = self.m_params.W\n",
    "        m_b = self.m_params.b\n",
    "        N = len(W)\n",
    "        for i in range(N):\n",
    "            m_W[i] = beta1*m_W[i] + (1-beta1)*grad_w[i]\n",
    "            u_W[i] = beta2*u_W[i] + (1-beta2)*np.square(grad_w[i])\n",
    "            m_hat_W = m_W[i]/(1.0-np.power(beta1,i+1))\n",
    "            u_hat_W = u_W[i]/(1.0-np.power(beta2,i+1))\n",
    "            W[i] = W[i] - (eta/(np.sqrt(u_hat_W)+epsilon))*m_hat_W\n",
    "            \n",
    "            m_b[i] = beta1*m_b[i] + (1-beta1)*grad_b[i]\n",
    "            u_b[i] = beta2*u_b[i] + (1-beta2)*np.square(grad_b[i])\n",
    "            m_hat_b = m_b[i]/(1.0-np.power(beta1,i+1))\n",
    "            u_hat_b = u_b[i]/(1.0-np.power(beta2,i+1))\n",
    "            b[i] = b[i] - (eta/(np.sqrt(u_hat_b)+epsilon))*m_hat_b\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nadam():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def update_nadam_params(self,eta,beta,beta1,beta2,epsilon,X,Y):\n",
    "        W = self.params.W\n",
    "        b = self.params.b\n",
    "        u_W = self.u_params.W\n",
    "        u_b = self.u_params.b\n",
    "        m_W = self.m_params.W\n",
    "        m_b = self.m_params.b\n",
    "        g_W = self.lookahead_params.W\n",
    "        g_b = self.lookahead_params.b\n",
    "        N = len(W)\n",
    "        \n",
    "        self.params.ForwardPropagation(X)\n",
    "        self.params.BackPropagation(X,Y)\n",
    "        \n",
    "        grad_w = self.params.grad_w\n",
    "        grad_b = self.params.grad_b\n",
    "        \n",
    "        for i in range(N):\n",
    "            g_W[i] = grad_w[i]\n",
    "            g_b[i] = grad_b[i]\n",
    "            \n",
    "        for i in range(N):\n",
    "            m_W[i] = beta1*m_W[i] + g_W[i]\n",
    "            m_b[i] = beta1*m_b[i] + g_b[i]\n",
    "            \n",
    "            u_W[i] = beta2*u_W[i] + (1-beta2)*np.square(grad_w[i])\n",
    "            u_b[i] = beta2*u_b[i] + (1-beta2)*np.square(grad_b[i])\n",
    "            \n",
    "            m_hat_W = (beta1*m_W[i] + g_W[i])/(1-np.power(beta1,i+1))\n",
    "            m_hat_b = (beta1*m_b[i] + g_b[i])/(1-np.power(beta1,i+1))\n",
    "            u_hat_W = u_W[i]/(1-np.power(beta2,i+1))\n",
    "            u_hat_b = u_b[i]/(1-np.power(beta2,i+1))\n",
    "            \n",
    "            W[i] = W[i] - (eta*m_hat_W/(np.sqrt(u_hat_W)+epsilon))\n",
    "            b[i] = b[i] - (eta*m_hat_b/(np.sqrt(u_hat_b)+epsilon))\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Your optimizer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class optimizer_name():\n",
    "    '''\n",
    "        Refer to the above optimizers for better understanding on how to use this class\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def update_optimizer_name_params(self,):\n",
    "        '''\n",
    "            Add your code to update parameters\n",
    "        '''\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    '''\n",
    "        weight_initializers : dictionary with random , xavier\n",
    "        weight_initializer : function\n",
    "        activation_funtions : dictionary with sigmoid, tanh, relu\n",
    "        der_activation_functions : dictionary with derivatives of the above\n",
    "        optimizer_funtions : dictionary with sgd, momentum, nesterov, rmsprop, adam, nadam}\n",
    "        activation : string\n",
    "        opitmizer : string\n",
    "        learning_rate : int\n",
    "        batch_size : int\n",
    "        num_epochs : int\n",
    "        num_features : dimension of X\n",
    "        num_hidden_layers : int, number of hidden layers\n",
    "        output_layer_dim : int\n",
    "        hidden_layer_dims : np.array with num_neurons in all hidden layer \n",
    "        weight_Decay : L2 regularisation\n",
    "        X_train : Training Data (n,d)\n",
    "        Y_train : Training Data (n,)\n",
    "        Xv : Validation Data (n,d)\n",
    "        Yv : Validation Data (n,)\n",
    "        hidden_layers : np.array of objects to class hidden_layer dimensions = num_hidden_layers\n",
    "        output_layer : object to hidden_layer class\n",
    "        params : It is a object of class parameter which has the weights and biases of the neural network\n",
    "        optimizer_object : object to the optimizer class, initialised in the initialize_neuralnet funciton\n",
    "        beta : momentum,neterov,rmsprop,nadam\n",
    "        beta1 : adam,nadam\n",
    "        beta2 : adam,nadam\n",
    "        epsilon : rmsprop,adam,nadam\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 num_features,\n",
    "                 weight_initializer,\n",
    "                 num_hidden_layers,\n",
    "                 hidden_layer_dims,\n",
    "                 optimizer,\n",
    "                 learning_rate,\n",
    "                 activation,\n",
    "                 X_train,\n",
    "                 Y_train,\n",
    "                 Xv,\n",
    "                 Yv,\n",
    "                 weight_decay,\n",
    "                 output_layer_dim,\n",
    "                 batch_size,\n",
    "                 num_epochs,\n",
    "                 loss = 'cross_entropy',\n",
    "                 output_activation = softmax,\n",
    "                 der_output_activation = der_softmax,\n",
    "                 beta=0.9,\n",
    "                 epsilon=1e-8,\n",
    "                 beta1=0.9,\n",
    "                 beta2=0.999):\n",
    "        self.weight_initializers = {\"random\": self.random_initialization, \"xavier\": self.xavier_intialization}\n",
    "        self.weight_initializer = self.weight_initializers[weight_initializer]\n",
    "        self.activation_functions = {\"sigmoid\": sigmoid, \"tanh\": tanh, \"ReLU\": relu}\n",
    "        self.der_activation_functions = {\"sigmoid\": der_sigmoid, \"tanh\": der_tanh, \"ReLU\": der_relu}\n",
    "        self.loss_functions = {'cross_entropy':self.Cross_Entropy_Loss,'mse' : self.Square_Error_Loss}\n",
    "        self.loss = self.loss_functions[loss]\n",
    "        '''\n",
    "            Add your optimizer function and class in the below dictionaries\n",
    "        '''\n",
    "        self.optimizer_functions = {\"sgd\": self.sgd, \"momentum\": self.momentum,\"nesterov\": self.nesterov, \"rmsprop\": self.rmsprop, \"adam\": self.adam, \"nadam\": self.nadam}\n",
    "        self.optimizer_classes = {\"sgd\": sgd, \"momentum\": momentum,\"nesterov\": nesterov, \"rmsprop\": rmsprop, \"adam\": adam, \"nadam\": nadam}\n",
    "        self.activation = self.activation_functions[activation]\n",
    "        self.optimizer = self.optimizer_functions[optimizer]\n",
    "        self.optimizer_class = self.optimizer_classes[optimizer]\n",
    "        self.der_activation = self.der_activation_functions[activation]\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.output_layer_dim = output_layer_dim\n",
    "        self.hidden_layer_dims = hidden_layer_dims\n",
    "        self.num_features = num_features\n",
    "        self.output_activation = output_activation\n",
    "        self.der_output_activation = der_output_activation\n",
    "        self.weight_decay = weight_decay\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.old_Y_train = Y_train\n",
    "        self.Xv = Xv\n",
    "        self.Yv = Yv\n",
    "        self.old_Yv = Yv\n",
    "        self.beta = beta\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.num_classes = self.output_layer_dim\n",
    "        # return self\n",
    "        \n",
    "    def Square_Error_Loss(self,Y_pred,Y_actual):\n",
    "        return np.mean((Y_pred-Y_actual)**2)\n",
    "    \n",
    "    def Cross_Entropy_Loss(self,Y_pred,Y_actual):\n",
    "        return (-1.0*np.sum(np.multiply(Y_actual+1,np.log(Y_pred+1))))/float(Y_pred.shape[0])\n",
    "    \n",
    "    def random_initialization(self, in_layer, out_layer):\n",
    "        return np.random.randn(in_layer, out_layer)\n",
    "\n",
    "    def xavier_intialization(self, in_layer, out_layer):\n",
    "        return np.random.randn(in_layer, out_layer)* np.sqrt(2 / (in_layer + out_layer))\n",
    "    \n",
    "    '''\n",
    "        The below optimizer functions are used to call the update_params methods in of their respective params\n",
    "    '''\n",
    "    \n",
    "    def sgd(self,X,Y):\n",
    "        sgd_obj = self.optimizer_object\n",
    "        parameters = self.params\n",
    "        parameters.ForwardPropagation(X)\n",
    "        parameters.BackPropagation(X,Y)\n",
    "        sgd_obj.update_sgd_params(self.learning_rate)\n",
    "        # for i in range(len(self.params.W)):\n",
    "        #     print(self.params.W[i])\n",
    "    \n",
    "    def momentum(self,X,Y):\n",
    "        momentum_obj = self.optimizer_object\n",
    "        parameters = self.params\n",
    "        parameters.ForwardPropagation(X)\n",
    "        parameters.BackPropagation(X,Y)\n",
    "        momentum_obj.updade_momentum_params(self.learning_rate,self.beta)\n",
    "\n",
    "    def nesterov(self,X,Y):\n",
    "        nesterov_obj = self.optimizer_object\n",
    "        nesterov_obj.update_nesterov_params(self.learning_rate,self.beta,X,Y)\n",
    "    \n",
    "    def rmsprop(self,X,Y):\n",
    "        rmsprop_obj = self.optimizer_object\n",
    "        parameters = self.params\n",
    "        parameters.ForwardPropagation(X)\n",
    "        parameters.BackPropagation(X,Y)\n",
    "        rmsprop_obj.update_rmsprop_params(self.learning_rate,self.beta,self.epsilon)\n",
    "    \n",
    "    def adam(self,X,Y):\n",
    "        adam_obj = self.optimizer_object\n",
    "        parameters = self.params\n",
    "        parameters.ForwardPropagation(X)\n",
    "        parameters.BackPropagation(X,Y)\n",
    "        adam_obj.update_adam_params(self.learning_rate,self.beta1,self.beta2,self.epsilon)\n",
    "    \n",
    "    def nadam(self,X,Y):\n",
    "        nadam_obj = self.optimizer_object\n",
    "        nadam_obj.update_nadam_params(self.learning_rate,self.beta,self.beta1,self.beta2,self.epsilon,X,Y)\n",
    "    \n",
    "    def optimzizer_name(self,X,Y):\n",
    "        '''\n",
    "            May implement forward and backpropagation here \n",
    "            Add code to create an object to your optimizer class\n",
    "            Then use this object to call your optimizer_update method \n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def sanitize_Y(self):\n",
    "        \n",
    "        temp = np.zeros((self.num_classes,self.Y_train.shape[0]))\n",
    "        for i in range(self.Y_train.shape[0]) :\n",
    "            temp[int(self.Y_train[i])][i] = 1\n",
    "        self.Y_train = temp\n",
    "        \n",
    "        temp = np.zeros((self.num_classes,self.Yv.shape[0]))\n",
    "        for i in range(self.Yv.shape[0]) :\n",
    "            temp[int(self.Yv[i])][i] = 1\n",
    "        self.Yv = temp\n",
    "        \n",
    "    def initialize_NeuralNet(self):\n",
    "        self.sanitize_Y()\n",
    "        self.optimizer_object = self.optimizer_class()\n",
    "        self.params = self.initialize_parameters()\n",
    "        self.optimizer_object.params = self.params\n",
    "        self.optimizer_object.u_params = self.zero_initializer()\n",
    "        self.optimizer_object.m_params = self.zero_initializer()\n",
    "        self.optimizer_object.lookahead_params = self.zero_initializer()\n",
    "        '''\n",
    "            can add required optimizer params and \n",
    "            initialize them here \n",
    "        '''\n",
    "        # pass\n",
    "    \n",
    "    \n",
    "    def add_hidden(self,num_neurons,pos):\n",
    "        '''\n",
    "        This function can be used to insert a layer at any position\n",
    "        (0 indexing)\n",
    "        '''\n",
    "        self.hidden_layer_dims.insert(pos,num_neurons)\n",
    "        self.num_hidden_layers += 1\n",
    "        \n",
    "    def zero_initializer(self):\n",
    "        params = Parameters()\n",
    "        W = []\n",
    "        b = []\n",
    "        in_layer, out_layer = self.num_features,self.hidden_layer_dims[1]\n",
    "        for i in range(self.num_hidden_layers):\n",
    "            if  i == 0:\n",
    "                in_layer = self.num_features\n",
    "            else:\n",
    "                in_layer = self.hidden_layer_dims[i-1]\n",
    "                \n",
    "            if i == self.num_hidden_layers-1:\n",
    "                out_layer = self.output_layer_dim\n",
    "            else:\n",
    "                out_layer = self.hidden_layer_dims[i+1]\n",
    "            W.append(np.zeros(shape = (self.hidden_layer_dims[i],in_layer)))\n",
    "            b.append(np.zeros(shape = (self.hidden_layer_dims[i],1)))\n",
    "        W.append(np.zeros(shape = (self.num_classes,self.hidden_layer_dims[self.num_hidden_layers-1])))\n",
    "        b.append(np.zeros(shape=(self.num_classes,1)))\n",
    "        params.W = W\n",
    "        params.b = b\n",
    "        params.activation = self.activation\n",
    "        params.output_activation = self.output_activation\n",
    "        params.der_activation = self.der_activation\n",
    "        params.weight_decay = self.weight_decay\n",
    "        return params\n",
    "    \n",
    "    def initialize_parameters(self):\n",
    "        params = Parameters()\n",
    "        W = []\n",
    "        b = []\n",
    "        in_layer, out_layer = self.num_features,self.hidden_layer_dims[1]\n",
    "        for i in range(self.num_hidden_layers):\n",
    "            if  i == 0:\n",
    "                in_layer = self.num_features\n",
    "            else:\n",
    "                in_layer = self.hidden_layer_dims[i-1]\n",
    "                \n",
    "            if i == self.num_hidden_layers-1:\n",
    "                out_layer = self.output_layer_dim\n",
    "            else:\n",
    "                out_layer = self.hidden_layer_dims[i+1]\n",
    "            W.append(self.weight_initializer(self.hidden_layer_dims[i],in_layer))\n",
    "            b.append(np.zeros(shape=(self.hidden_layer_dims[i],1)))\n",
    "        W.append(self.weight_initializer(self.num_classes,self.hidden_layer_dims[self.num_hidden_layers-1]))\n",
    "        b.append(np.zeros(shape=(self.num_classes,1)))\n",
    "        params.W = W\n",
    "        params.b = b\n",
    "        params.activation = self.activation\n",
    "        params.output_activation = self.output_activation\n",
    "        params.der_activation = self.der_activation\n",
    "        params.weight_decay = self.weight_decay\n",
    "        return params\n",
    "    \n",
    "    def fit_NeuralNet(self):\n",
    "        self.initialize_NeuralNet()\n",
    "        for curr_epoch in range(self.num_epochs):\n",
    "            print(\"Epoch Number : \",curr_epoch+1)  \n",
    "            for i in range(0,self.X_train.shape[1],self.batch_size):\n",
    "                curr_batch = min(self.X_train.shape[1]-i,self.batch_size)\n",
    "                self.optimizer(self.X_train[:,i:i+curr_batch],self.Y_train[:,i:i+curr_batch])\n",
    "            train_acc,validation_acc,training_loss,validation_loss = self.accuracy_NeuralNet(self.old_Y_train,self.old_Yv)\n",
    "            print(\"train accuracy =\",train_acc,\", validation accuracy =\",validation_acc,\", training loss =\",training_loss,\", validation loss =\",validation_loss)\n",
    "        # pass\n",
    "    \n",
    "    def predict_NeuralNet(self,X):\n",
    "        self.params.ForwardPropagation(X)\n",
    "        Y_pred = np.argmax(self.params.H[len(self.params.H)-1],axis=0)\n",
    "        return Y_pred\n",
    "    \n",
    "    def accuracy_NeuralNet(self,Y_train,Yv):\n",
    "        Y_train_pred = self.predict_NeuralNet(self.X_train)\n",
    "        Yv_pred = self.predict_NeuralNet(self.Xv)\n",
    "        training_Loss = self.loss(Y_train_pred,self.old_Y_train)\n",
    "        validation_Loss = self.loss(Yv_pred,self.old_Yv)\n",
    "        return self.accuracy_score(Y_train_pred,Y_train),self.accuracy_score(Yv_pred,Yv),training_Loss,validation_Loss\n",
    "    \n",
    "    def accuracy_score(self, Y_pred, Y_train):\n",
    "        return np.sum(Y_pred == Y_train)/Y_train.shape[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  1\n",
      "train accuracy = 0.958037037037037 , validation accuracy = 0.9528333333333333 , training loss = -10.009037257098214 , validation loss = -9.9658372948867\n",
      "Epoch Number :  2\n",
      "train accuracy = 0.963925925925926 , validation accuracy = 0.9551666666666667 , training loss = -9.980902002442695 , validation loss = -9.918652277126508\n",
      "Epoch Number :  3\n",
      "train accuracy = 0.9721666666666666 , validation accuracy = 0.957 , training loss = -10.007618834893005 , validation loss = -9.928668255660954\n",
      "Epoch Number :  4\n",
      "train accuracy = 0.9699814814814814 , validation accuracy = 0.9525 , training loss = -10.01906362096651 , validation loss = -9.949447033774408\n",
      "Epoch Number :  5\n",
      "train accuracy = 0.9761481481481481 , validation accuracy = 0.9536666666666667 , training loss = -10.064178837233332 , validation loss = -9.981954767382144\n",
      "Test Accuracy : 0.9545\n"
     ]
    }
   ],
   "source": [
    "NUM_FEATURES = X_train.shape[0]\n",
    "WEIGHT_INITIALIZER = \"xavier\"\n",
    "NUM_HIDDEN_LAYERS = 5\n",
    "# HIDDEN_LAYER_DIMS = (128+np.arange(NUM_HIDDEN_LAYERS)).astype(int)\n",
    "HIDDEN_LAYER_DIMS = (128+np.zeros(NUM_HIDDEN_LAYERS)).astype(int)\n",
    "OPTIMIZER = \"adam\"\n",
    "LEARNING_RATE = 0.001\n",
    "ACTIVATION = \"ReLU\"\n",
    "OUTPUT_LAYER_DIM = num_classes\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "WEIGHT_DECAY = 0.0005\n",
    "\n",
    "N = NeuralNet(num_features = NUM_FEATURES,\n",
    "                weight_initializer = WEIGHT_INITIALIZER,\n",
    "                num_hidden_layers = NUM_HIDDEN_LAYERS,\n",
    "                hidden_layer_dims = HIDDEN_LAYER_DIMS,\n",
    "                optimizer = OPTIMIZER,\n",
    "                learning_rate = LEARNING_RATE,\n",
    "                activation = ACTIVATION,\n",
    "                X_train = X_train,\n",
    "                Y_train = Y_train,\n",
    "                Xv = Xv,\n",
    "                Yv = Yv,\n",
    "                # loss = 'mse',\n",
    "                weight_decay=WEIGHT_DECAY,\n",
    "                output_layer_dim = OUTPUT_LAYER_DIM,\n",
    "                batch_size = BATCH_SIZE,\n",
    "                num_epochs = EPOCHS)\n",
    "N.fit_NeuralNet()\n",
    "Y_pred_test = N.predict_NeuralNet(X_test)\n",
    "print(\"Test Accuracy :\",N.accuracy_score(Y_pred_test,Y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  1\n",
      "train accuracy = 0.960925925925926 , validation accuracy = 0.9546666666666667 , training loss = -10.048537462480517 , validation loss = -9.987586375713231\n",
      "Epoch Number :  2\n",
      "train accuracy = 0.9711666666666666 , validation accuracy = 0.959 , training loss = -10.047220306192362 , validation loss = -9.990628110135924\n",
      "Epoch Number :  3\n",
      "train accuracy = 0.9757407407407407 , validation accuracy = 0.9623333333333334 , training loss = -10.045519693697043 , validation loss = -9.982681763410081\n",
      "Epoch Number :  4\n",
      "train accuracy = 0.9732592592592593 , validation accuracy = 0.9568333333333333 , training loss = -10.037225221765482 , validation loss = -9.9592550765272\n",
      "Epoch Number :  5\n",
      "train accuracy = 0.977037037037037 , validation accuracy = 0.958 , training loss = -10.064965220465396 , validation loss = -9.999068151766087\n",
      "Test Accuracy : 0.959\n"
     ]
    }
   ],
   "source": [
    "NUM_FEATURES = X_train.shape[0]\n",
    "WEIGHT_INITIALIZER = \"xavier\"\n",
    "NUM_HIDDEN_LAYERS = 5\n",
    "# HIDDEN_LAYER_DIMS = (128+np.arange(NUM_HIDDEN_LAYERS)).astype(int)\n",
    "HIDDEN_LAYER_DIMS = (128+np.zeros(NUM_HIDDEN_LAYERS)).astype(int)\n",
    "OPTIMIZER = \"nadam\"\n",
    "LEARNING_RATE = 0.001\n",
    "ACTIVATION = \"ReLU\"\n",
    "OUTPUT_LAYER_DIM = num_classes\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "WEIGHT_DECAY = 0.0005\n",
    "\n",
    "N = NeuralNet(num_features = NUM_FEATURES,\n",
    "                weight_initializer = WEIGHT_INITIALIZER,\n",
    "                num_hidden_layers = NUM_HIDDEN_LAYERS,\n",
    "                hidden_layer_dims = HIDDEN_LAYER_DIMS,\n",
    "                optimizer = OPTIMIZER,\n",
    "                learning_rate = LEARNING_RATE,\n",
    "                activation = ACTIVATION,\n",
    "                X_train = X_train,\n",
    "                Y_train = Y_train,\n",
    "                Xv = Xv,\n",
    "                Yv = Yv,\n",
    "                # loss = 'mse',\n",
    "                weight_decay=WEIGHT_DECAY,\n",
    "                output_layer_dim = OUTPUT_LAYER_DIM,\n",
    "                batch_size = BATCH_SIZE,\n",
    "                num_epochs = EPOCHS)\n",
    "N.fit_NeuralNet()\n",
    "Y_pred_test = N.predict_NeuralNet(X_test)\n",
    "print(\"Test Accuracy :\",N.accuracy_score(Y_pred_test,Y_test))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  1\n",
      "train accuracy = 0.9615370370370371 , validation accuracy = 0.9543333333333334 , training loss = -10.041885905482662 , validation loss = -9.988050275319605\n",
      "Epoch Number :  2\n",
      "train accuracy = 0.9756481481481482 , validation accuracy = 0.9676666666666667 , training loss = -10.042662895416518 , validation loss = -9.963546336130717\n",
      "Epoch Number :  3\n",
      "train accuracy = 0.9781666666666666 , validation accuracy = 0.9633333333333334 , training loss = -10.081321511464983 , validation loss = -10.008633740307971\n",
      "Test Accuracy : 0.9661\n"
     ]
    }
   ],
   "source": [
    "NUM_FEATURES = X_train.shape[0]\n",
    "WEIGHT_INITIALIZER = \"xavier\"\n",
    "NUM_HIDDEN_LAYERS = 3\n",
    "# HIDDEN_LAYER_DIMS = (128+np.arange(NUM_HIDDEN_LAYERS)).astype(int)\n",
    "HIDDEN_LAYER_DIMS = (128+np.zeros(NUM_HIDDEN_LAYERS)).astype(int)\n",
    "OPTIMIZER = \"nesterov\"\n",
    "LEARNING_RATE = 0.001\n",
    "ACTIVATION = \"ReLU\"\n",
    "OUTPUT_LAYER_DIM = num_classes\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 3\n",
    "WEIGHT_DECAY = 0.0005\n",
    "\n",
    "N = NeuralNet(num_features = NUM_FEATURES,\n",
    "                weight_initializer = WEIGHT_INITIALIZER,\n",
    "                num_hidden_layers = NUM_HIDDEN_LAYERS,\n",
    "                hidden_layer_dims = HIDDEN_LAYER_DIMS,\n",
    "                optimizer = OPTIMIZER,\n",
    "                learning_rate = LEARNING_RATE,\n",
    "                activation = ACTIVATION,\n",
    "                X_train = X_train,\n",
    "                Y_train = Y_train,\n",
    "                Xv = Xv,\n",
    "                Yv = Yv,\n",
    "                # loss = 'mse',\n",
    "                weight_decay=WEIGHT_DECAY,\n",
    "                output_layer_dim = OUTPUT_LAYER_DIM,\n",
    "                batch_size = BATCH_SIZE,\n",
    "                num_epochs = EPOCHS)\n",
    "N.fit_NeuralNet()\n",
    "Y_pred_test = N.predict_NeuralNet(X_test)\n",
    "print(\"Test Accuracy :\",N.accuracy_score(Y_pred_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    learning_rate = 0.001,0.0001\\n    weight_decay = 0.0001,0.0005,0.001\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N.accuracy_NeuralNet(Y_train,Yv)\n",
    "'''\n",
    "    learning_rate = 0.001,0.0001\n",
    "    weight_decay = 0.0001,0.0005,0.001\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Y_pred_test = N.predict_NeuralNet(X_test)\n",
    "# print(accuracy_score(y_pred=Y_pred_test,y_true=Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # config_defaults = {\n",
    "    #     \"num_epochs\" : 10,\n",
    "    #     \"batch_size\" : 64,\n",
    "    #     \"learning_rate\" : 0.001,\n",
    "    #     \"activation\" : \"ReLU\",\n",
    "    #     \"optimizer\" : \"adam\",\n",
    "    #     \"weight_intializer\" : \"xavier\",\n",
    "    #     \"weight_decay\" : 0,\n",
    "    #     \"hidden_layer_size\" : 64,\n",
    "    #     \"num_hidden_layers\" : 3,\n",
    "    # }\n",
    "    \n",
    "    # wandb.init(config=config_defaults)\n",
    "    wandb.init()\n",
    "    config = wandb.config\n",
    "    HIDDEN_LAYER_SIZE = config.hidden_layer_size\n",
    "    NUM_FEATURES = X_train.shape[0]\n",
    "    WEIGHT_INITIALIZER = config.weight_initializer\n",
    "    NUM_HIDDEN_LAYERS = config.num_hidden_layers\n",
    "    HIDDEN_LAYER_DIMS = (config.hidden_layer_size+np.zeros(NUM_HIDDEN_LAYERS)).astype(int)\n",
    "    OPTIMIZER = config.optimizer\n",
    "    LEARNING_RATE = config.learning_rate\n",
    "    ACTIVATION = config.activation\n",
    "    OUTPUT_LAYER_DIM = num_classes\n",
    "    BATCH_SIZE = config.batch_size\n",
    "    EPOCHS = config.num_epochs\n",
    "    WEIGHT_DECAY = config.weight_decay\n",
    "    print(\"dkcndidc\")\n",
    "    run_name = \"op_{}_ac_{}_wi_{}_lr_{}_bs_{}_l2_{}_nh_{}_sh_{}_ep_{}\".format(OPTIMIZER,ACTIVATION,WEIGHT_INITIALIZER,LEARNING_RATE,BATCH_SIZE,WEIGHT_DECAY,NUM_HIDDEN_LAYERS,HIDDEN_LAYER_SIZE,EPOCHS)\n",
    "    \n",
    "    FFN = NeuralNet(num_features = NUM_FEATURES,\n",
    "                    weight_initializer = WEIGHT_INITIALIZER,\n",
    "                    num_hidden_layers = NUM_HIDDEN_LAYERS,\n",
    "                    hidden_layer_dims = HIDDEN_LAYER_DIMS,\n",
    "                    optimizer = OPTIMIZER,\n",
    "                    learning_rate = LEARNING_RATE,\n",
    "                    activation = ACTIVATION,\n",
    "                    X_train = X_train,\n",
    "                    Y_train = Y_train,\n",
    "                    Xv = Xv,\n",
    "                    Yv = Yv,\n",
    "                    weight_decay=WEIGHT_DECAY,\n",
    "                    output_layer_dim = OUTPUT_LAYER_DIM,\n",
    "                    batch_size = BATCH_SIZE,\n",
    "                    num_epochs = EPOCHS)\n",
    "    \n",
    "    FFN.fit_NeuralNet()\n",
    "    train_acc,validation_acc = FFN.accuracy_NeuralNet(Y_train,Yv)\n",
    "    Y_pred_test = FFN.predict_NeuralNet(X_test)\n",
    "    \n",
    "    print(\"Test Accuracy :\",accuracy_score(Y_pred_test,Y_test))\n",
    "    wandb.log({\"training_accuracy\" : train_acc,\n",
    "               \"validation_accuracy\" : validation_acc})\n",
    "    wandb.run.name = run_name\n",
    "    wandb.run.save()\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    # \"name\" : \"sweeps\"\n",
    "    \"method\" : \"bayes\",\n",
    "    \"metric\" :{\n",
    "        \"name\" : \"validation_accuracy\",\n",
    "        \"goal\" : \"maximize\"\n",
    "    },\n",
    "    \"parameters\" : {\n",
    "        \"num_epochs\" : {\n",
    "            \"values\" : [5,10]\n",
    "        },\n",
    "        \"num_hidden_layers\" : {\n",
    "            \"values\" : [ 3, 4, 5]\n",
    "        },\n",
    "        \"hidden_layer_size\" : {\n",
    "            \"values\" : [32, 64, 128]\n",
    "        },\n",
    "        \"weight_decay\" : {\n",
    "            \"values\" : [0.0001,0.0005,0.001]\n",
    "        },\n",
    "        \"learning_rate\" : {\n",
    "            \"values\" : [0.001,0.0001]\n",
    "        },\n",
    "        \"optimizer\" : {\n",
    "           \"values\" : [\"sgd\", \"momentum\", \"nesterov\", \"rmsprop\", \"adam\", \"nadam\"] \n",
    "        },\n",
    "        \"batch_size\" : {\n",
    "            \"values\" : [128,256,512]\n",
    "        },\n",
    "        \"weight_initializer\" : {\n",
    "            \"values\" : [\"random\",\"xavier\"]\n",
    "        },\n",
    "        \"activation\" : {\n",
    "            \"values\" : [\"sigmoid\", \"tanh\", \"ReLU\"]\n",
    "        },\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: crsaivfz\n",
      "Sweep URL: https://wandb.ai/cs20b009/CS6910_Assignment_1/sweeps/crsaivfz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: gzdwbqss with config:\n",
      "wandb: \tactivation: ReLU\n",
      "wandb: \tbatch_size: 128\n",
      "wandb: \thidden_layer_size: 64\n",
      "wandb: \tlearning_rate: 0.001\n",
      "wandb: \tnum_epochs: 5\n",
      "wandb: \tnum_hidden_layers: 5\n",
      "wandb: \toptimizer: rmsprop\n",
      "wandb: \tweight_decay: 0.001\n",
      "wandb: \tweight_initializer: xavier\n",
      "wandb: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: /tmp/ipykernel_3504/2186392851.py 15 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/arunesh/.local/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\", line 1133, in init\n",
      "    wandb._assert_is_user_process()\n",
      "  File \"/home/arunesh/.local/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\", line 730, in init\n",
      "    run._set_run_obj_offline(run_proto)\n",
      "  File \"/home/arunesh/.local/lib/python3.8/site-packages/wandb/sdk/lib/mailbox.py\", line 273, in wait\n",
      "    if on_probe:\n",
      "  File \"/home/arunesh/.local/lib/python3.8/site-packages/wandb/sdk/lib/mailbox.py\", line 120, in _get_and_clear\n",
      "    self._wait_all = wait_all\n",
      "  File \"/home/arunesh/.local/lib/python3.8/site-packages/wandb/sdk/lib/mailbox.py\", line 116, in _wait\n",
      "    self._abandoned = False\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 558, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 306, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "Exception\n",
      "wandb: ERROR Abnormal program exit\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config,project=\"CS6910_Assignment_1\")\n",
    "wandb.agent(sweep_id=sweep_id,function=train,count = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
